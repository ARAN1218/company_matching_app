import streamlit as st
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
import plotly.graph_objects as go
import os
# from PIL import Image
# LangChain & Google Generative AI é–¢é€£
from langchain_google_genai import ChatGoogleGenerativeAI
# from langchain.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import google.api_core.exceptions
import gyoukai
import gyoukai_info
import slider_captions
industries_list = gyoukai.INDUSTRIES_LIST
industry_intros = gyoukai_info.INDUSTRIES_INFO
slider_captions = slider_captions.SLIDER_CAPTIONS

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€(ãƒ†ã‚¹ãƒˆæ™‚ã®ã¿æœ‰åŠ¹)
# from dotenv import load_dotenv
# load_dotenv()
# file_id = os.environ.get("COMPANY_FILE_ID")
# gemini_api_key = os.environ.get("GEMINI_API_KEY")

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€(æœ¬ç•ªæ™‚ã®ã¿æœ‰åŠ¹)
file_id = st.secrets["COMPANY_FILE_ID"]
gemini_api_key = st.secrets["GEMINI_API_KEY"]


# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨è¨­å®š
# ç”»åƒã‚‚è¨­å®šã§ãã‚‹ï¼šfavicon = Image.open("favicon.ico")
st.set_page_config(
    page_title="ä¼æ¥­ãƒ»æ¥­ç•Œãƒãƒƒãƒãƒ³ã‚°ã‚¢ãƒ—ãƒª",
    page_icon="ğŸ¢",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.title('ğŸ” ä¼æ¥­ãƒ»æ¥­ç•Œãƒãƒƒãƒãƒ³ã‚°ã‚¢ãƒ—ãƒª')
st.write('âœ¨ ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã«åˆã£ãŸä¼æ¥­ã‚„æ¥­ç•Œã‚’è¦‹ã¤ã‘ã¾ã—ã‚‡ã†ï¼')

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç† ---
@st.cache_data
def load_data():
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        # search result [1] ã‚’å‚ç…§
        url = f"https://drive.google.com/uc?id={file_id}"
        df = pd.read_csv(url)
    except FileNotFoundError:
        st.error("ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
        st.stop()

    # æ¯”è¼ƒã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡
    features = ["å¾…é‡é¢ã®æº€è¶³åº¦","ç¤¾å“¡ã®å£«æ°—","é¢¨é€šã—ã®è‰¯ã•","ç¤¾å“¡ã®ç›¸äº’å°Šé‡",
                "20ä»£æˆé•·ç’°å¢ƒ","äººæã®é•·æœŸè‚²æˆ","æ³•ä»¤é †å®ˆæ„è­˜","äººäº‹è©•ä¾¡ã®é©æ­£æ„Ÿ"]
    display_numerical_features = ['å¹³å‡å¹´å', 'æ®‹æ¥­æ™‚é–“(æœˆé–“)', 'æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡']

    # æ¬ æå€¤å‡¦ç† & ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    df = df.dropna(subset=features)
    for col in features:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.dropna(subset=features)
    for col in features:
        df = df[(df[col] >= 1) & (df[col] <= 5)]

    # å‚è€ƒæ•°å€¤ãƒ‡ãƒ¼ã‚¿å‡¦ç†
    for col in display_numerical_features:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        else:
            df[col] = np.nan

    # ä¼æ¥­åãƒªã‚¹ãƒˆã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¼æ¥­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    company_names_list = sorted(df['ä¼æ¥­å'].unique().tolist())
    default_company_name = "ãƒ‡ãƒ­ã‚¤ãƒˆãƒˆãƒ¼ãƒãƒ„ãƒªã‚¹ã‚¯ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªãƒ¼åˆåŒä¼šç¤¾"
    try:
        default_company_index = company_names_list.index(default_company_name)
    except ValueError:
        default_company_index = 0

    return df, features, display_numerical_features, company_names_list, default_company_index

df, features, display_numerical_features, company_names_list, default_company_index = load_data()

# æ¥­ç•Œãƒªã‚¹ãƒˆ
all_industries_options = ['å…¨æ¥­ç•Œ'] + industries_list
industries_for_analysis = industries_list

# --- æ¥­ç•Œã”ã¨ã®å¹³å‡å€¤è¨ˆç®— ---
@st.cache_data
def calculate_industry_averages(_df, _industries_for_analysis, _features, _display_numerical_features):
    industry_avg = {}
    # å…¨æ¥­ç•Œ
    industry_avg['å…¨æ¥­ç•Œ'] = {}
    for feature in _features:
        industry_avg['å…¨æ¥­ç•Œ'][feature] = _df[feature].mean()
    for num_feature in _display_numerical_features:
        industry_avg['å…¨æ¥­ç•Œ'][num_feature] = _df[num_feature].mean(skipna=True)
    # å„æ¥­ç•Œ
    for industry in _industries_for_analysis:
        industry_data = _df[_df['æ¥­ç•Œ'] == industry]
        if not industry_data.empty:
            avg_values = {}
            for feature in _features:
                avg_values[feature] = industry_data[feature].mean()
            for num_feature in _display_numerical_features:
                 avg_values[num_feature] = industry_data[num_feature].mean(skipna=True)
            industry_avg[industry] = avg_values
    return industry_avg

industry_avg = calculate_industry_averages(df, industries_for_analysis, features, display_numerical_features)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.header('ğŸ”§ å…±é€šæ¡ä»¶è¨­å®š')
app_mode = st.sidebar.radio(
    "ğŸ“‹ æ©Ÿèƒ½ã‚’é¸æŠ",
    ["ğŸ” ä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°", "ğŸ“Š æ¥­ç•Œãƒãƒƒãƒãƒ³ã‚°", "ğŸ”„ ä¼æ¥­æ¯”è¼ƒ", "ğŸŒ æ¥­ç•Œæ¯”è¼ƒ", "ğŸ“ˆ æ¥­ç•Œãƒ»ä¼æ¥­åˆ†æ"],
    key='app_mode_radio'
)

selected_industry_filter = st.sidebar.selectbox('çµã‚Šè¾¼ã¿æ¥­ç•Œã‚’é¸æŠï¼ˆä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°ç”¨ï¼‰', all_industries_options, key='common_industry_filter')
st.sidebar.subheader('ğŸ¯ ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (å„1ã€œ5ç‚¹)')
st.sidebar.caption("å„é …ç›®ã«ã¤ã„ã¦ã€ã‚ãªãŸãŒä¼æ¥­ã‚„æ¥­ç•Œã«æ±‚ã‚ã‚‹åº¦åˆã„ã‚’1(ä½ã„)ã€œ5(é«˜ã„)ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
user_preferences = {}
for feature in features:
    user_preferences[feature] = st.sidebar.markdown(f"**{feature}**")  # ã‚¿ã‚¤ãƒˆãƒ«
    st.sidebar.caption(slider_captions.get(feature, ""))  # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè–„ã„æ–‡å­—ï¼‰
    user_preferences[feature] = st.sidebar.slider(
        " ",  # ãƒ©ãƒ™ãƒ«ã¯ç©ºã«ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã ã‘è¡¨ç¤º
        1.0, 5.0, 3.0, 0.1, key=f"common_{feature}"
    )

# --- å…±é€šé–¢æ•° ---
# ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆæç”» (å¤‰æ›´ãªã—)
def plot_radar_chart(data_list, labels, chart_title, categories=None):
    if categories is None: categories = features
    fig = go.Figure()
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
    valid_data_found = False
    for i, (data, label) in enumerate(zip(data_list, labels)):
        if data is None or len(data) != len(categories):
            st.warning(f"è­¦å‘Š: ã€Œ{label}ã€ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒä¸æ­£ã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã‚°ãƒ©ãƒ•ã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚")
            continue
        valid_data_found = True
        data_closed = list(data) + [data[0]]
        categories_closed = categories + [categories[0]]
        fig.add_trace(go.Scatterpolar(r=data_closed, theta=categories_closed, fill='toself', name=label, line_color=colors[i % len(colors)], opacity=0.6, hovertemplate='<b>%{theta}</b>: %{r:.2f}<extra></extra>'))
    if not valid_data_found:
        st.warning("ã‚°ãƒ©ãƒ•ã«è¡¨ç¤ºã§ãã‚‹æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[1, 5.1], tickvals=[1, 2, 3, 4, 5], tickfont=dict(size=10)), angularaxis=dict(tickfont=dict(size=11))), title=dict(text=chart_title, font=dict(size=16)), showlegend=True, legend=dict(font=dict(size=11), yanchor="bottom", y=-0.2, xanchor="center", x=0.5, orientation="h"), height=450, margin=dict(l=60, r=60, t=80, b=80))
    return fig

# ãƒ™ã‚¯ãƒˆãƒ«åŒ–é–¢æ•° (å¤‰æ›´ãªã—)
def get_company_vector(company_data):
    if company_data is None: return None
    if isinstance(company_data, pd.Series): vector = [company_data.get(feature, 3.0) for feature in features]
    elif isinstance(company_data, dict): vector = [company_data.get(feature, 3.0) for feature in features]
    else: return None
    vector = [v if isinstance(v, (int, float)) and 1 <= v <= 5 else 3.0 for v in vector]
    return vector

def get_user_vector(user_prefs):
    if user_prefs is None: return None
    vector = [user_prefs.get(feature, 3.0) for feature in features]
    vector = [v if isinstance(v, (int, float)) else 3.0 for v in vector]
    return vector

def get_industry_vector(industry_avg_data):
    if industry_avg_data is None: return None
    vector = [industry_avg_data.get(feature, 3.0) for feature in features]
    vector = [v if pd.notna(v) and isinstance(v, (int, float)) else 3.0 for v in vector]
    return vector

# ãŠã™ã™ã‚åº¦è¨ˆç®—é–¢æ•°
def calculate_recommend_scores(user_vector, target_vectors):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ™ã‚¯ãƒˆãƒ«ç¾¤ã«ã¤ã„ã¦ã€
    â‘ ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ï¼ˆ0-50ã«æ­£è¦åŒ–ï¼‰
    â‘¡ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼ˆ0-50ã«æ­£è¦åŒ–ï¼‰
    ã‚’åˆç®—ã—ã¦100ç‚¹æº€ç‚¹ã®ãŠã™ã™ã‚åº¦ã‚’è¨ˆç®—
    """
    if user_vector is None or target_vectors is None or len(target_vectors) == 0:
        return np.array([])

    # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢è¨ˆç®—
    user_vectors_repeated = np.tile(user_vector, (len(target_vectors), 1))
    euclidean_distances = np.linalg.norm(target_vectors - user_vectors_repeated, axis=1)

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
    cosine_similarities = cosine_similarity([user_vector], target_vectors).flatten()

    # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’0-50ã«æ­£è¦åŒ–ï¼ˆè·é›¢ãŒå°ã•ã„ã»ã©é«˜ã‚¹ã‚³ã‚¢ï¼‰
    if np.all(euclidean_distances == euclidean_distances[0]):
        euclidean_scores = np.full_like(euclidean_distances, 50.0)
    else:
        euclidean_scaler = MinMaxScaler(feature_range=(0, 50))
        euclidean_scores = 50.0 - euclidean_scaler.fit_transform(euclidean_distances.reshape(-1, 1)).flatten()

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’0-50ã«æ­£è¦åŒ–
    if np.all(cosine_similarities == cosine_similarities[0]):
        cosine_scores = np.full_like(cosine_similarities, 50.0)
    else:
        cosine_scaler = MinMaxScaler(feature_range=(0, 50))
        cosine_scores = cosine_scaler.fit_transform(cosine_similarities.reshape(-1, 1)).flatten()

    # åˆç®—ï¼ˆæœ€å¤§100ç‚¹ï¼‰
    recommend_scores = euclidean_scores + cosine_scores

    return recommend_scores

# --- Gemini èª¬æ˜ç”Ÿæˆé–¢æ•° (LCELå½¢å¼ã«ä¿®æ­£) ---
@st.cache_data
def generate_company_descriptions(companies, api_key):
    """Gemini APIã‚’ä½¿ã£ã¦è¤‡æ•°ã®ä¼æ¥­ã®èª¬æ˜æ–‡ã‚’ä¸€åº¦ã«ç”Ÿæˆã™ã‚‹ (LCELç‰ˆ)"""
    if not api_key:
        return ["APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“."] * len(companies)

    try:
        # LLMã®åˆæœŸåŒ–
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.7, convert_system_message_to_human=False, google_api_key=api_key)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        template = """
        ã‚ãªãŸã¯å°±æ´»ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸä¼æ¥­æƒ…å ±ã‚’ã‚‚ã¨ã«ã€å„ä¼æ¥­ã¸ã®å¿œå‹Ÿã‚’æ¤œè¨ã—ã¦ã„ã‚‹å­¦ç”Ÿã«å‘ã‘ã¦ã€80æ–‡å­—ä»¥å†…ã§ãã®ä¼æ¥­ã®é­…åŠ›ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚
        {company_details}
        """
        # prompt = PromptTemplate(template=template, input_variables=["company_details"])
        prompt = ChatPromptTemplate.from_template(template)

        # LCELãƒã‚§ãƒ¼ãƒ³
        chain = prompt | llm | StrOutputParser()

        # ä¼æ¥­æƒ…å ±ã‚’æ•´å½¢
        company_details = ""
        for company in companies:
            company_scores = "\n".join([f"- {feat}: {company[feat]:.1f}ç‚¹" for feat in features])
            company_details += f"ä¼æ¥­å: {company['ä¼æ¥­å']}\næ¥­ç•Œ: {company['æ¥­ç•Œ']}\nè©•ä¾¡ã‚¹ã‚³ã‚¢ (5ç‚¹æº€ç‚¹):\n{company_scores}\n\n"

        # å‘¼ã³å‡ºã—
        response = chain.invoke({"company_details": company_details})

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¼æ¥­ã”ã¨ã«åˆ†å‰²
        # descriptions = response.strip().split("\n\n")
        return response

    except google.api_core.exceptions.PermissionDenied as e:
        st.error(f"APIã‚­ãƒ¼ãŒç„¡åŠ¹ã‹ã€æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“: {e}")
        return ["APIã‚­ãƒ¼ãŒç„¡åŠ¹ã€ã¾ãŸã¯APIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“."] * len(companies)
    except Exception as e:
        st.error(f"AIã«ã‚ˆã‚‹èª¬æ˜ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return ["AIã«ã‚ˆã‚‹èª¬æ˜ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ."] * len(companies)

def format_compare_value(company, item):
    val = company.get(item, np.nan);
    if pd.isna(val): return "N/A"
    if item == 'ãŠã™ã™ã‚åº¦': return f"{val:.2f}"
    if item == 'ç·åˆè©•ä¾¡': return f"{val:.2f}"
    if item == 'å¹³å‡å¹´å': return f"{val:.0f}ä¸‡å††"
    if item == 'æ®‹æ¥­æ™‚é–“(æœˆé–“)': return f"{val:.1f}æ™‚é–“"
    if item == 'æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡': return f"{val:.1f}%"
    if item in features: return f"{val:.2f}"
    return str(val)

def format_industry_compare_value(avg_data, item):
    if avg_data is None: return "N/A"
    value = avg_data.get(item, np.nan)
    if pd.isna(value): return "N/A"
    if item in features: return f"{value:.2f}"
    if item == 'å¹³å‡å¹´å': return f"{value:.0f}ä¸‡å††"
    if item == 'æ®‹æ¥­æ™‚é–“(æœˆé–“)': return f"{value:.1f}æ™‚é–“"
    if item == 'æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡': return f"{value:.1f}%"
    return f"{value:.2f}"

# --- æ©Ÿèƒ½ã”ã¨ã®å®Ÿè£… ---
# --- ä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°æ©Ÿèƒ½ ---
if app_mode == "ğŸ” ä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°":
    st.header('ğŸ” ä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°')
    st.write("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ã—ãŸå¸Œæœ›æ¡ä»¶ã«åŸºã¥ãã€ãŠã™ã™ã‚ã®ä¼æ¥­ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

    # AIåˆ©ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    use_ai_description = st.checkbox("AIã«ã‚ˆã‚‹ä¼æ¥­ç´¹ä»‹æ–‡ã‚’ç”Ÿæˆã™ã‚‹", value=True, key='use_ai_description')

    if selected_industry_filter != 'å…¨æ¥­ç•Œ':
        filtered_df = df[df['æ¥­ç•Œ'] == selected_industry_filter].copy()
        st.write(f"**çµã‚Šè¾¼ã¿æ¥­ç•Œ:** {selected_industry_filter}")
        if filtered_df.empty:
            st.warning(f"ã€Œ{selected_industry_filter}ã€æ¥­ç•Œã«è©²å½“ã™ã‚‹ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        filtered_df = df.copy()
        st.write(f"**çµã‚Šè¾¼ã¿æ¥­ç•Œ:** å…¨æ¥­ç•Œ")
    search_button = st.sidebar.button('ğŸ” ãƒãƒƒãƒãƒ³ã‚°é–‹å§‹', key='match_company_button')

    # Geminiä¸€æ‹¬èª¬æ˜æ–‡ç”Ÿæˆ
    def generate_bulk_company_descriptions(companies, api_key):
        try:
            llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.7, convert_system_message_to_human=False, google_api_key=api_key)
            from langchain_core.prompts import ChatPromptTemplate
            from langchain_core.output_parsers import StrOutputParser
            template = (
                """
                [ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ]
                ã‚ãªãŸã¯å°±æ´»ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã®ã‚¢ã‚¤å…ˆç”Ÿã§ã™ã€‚ã“ã‚Œã¾ã§ä½•äººã‚‚ã®å¤§å’å°±æ´»ç”Ÿã‚’è‡ªåˆ†ã«åˆã£ãŸä¼æ¥­ã«åˆæ ¼ã•ã›ã¦ãã¾ã—ãŸã€‚ã‚¢ã‚¤å…ˆç”Ÿã®å¼·ã¿ã¯ãã®åœ§å€’çš„ä¼æ¥­åˆ†æåŠ›ã§ã‚ã‚Šã€ä¼æ¥­ã®å¼·ã¿ã‚’è¦ç´„ã—ã¦äººã«ä¼ãˆã‚‹äº‹ã«é–¢ã—ã¦ã¯å…¨äººé¡ã®ä¸­ã§ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®å®ŸåŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
                
                [ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ]
                ï¼œæŒ‡ç¤ºï¼
                ä»¥ä¸‹ã®ä¼æ¥­ç¾¤ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€å„ä¼æ¥­ã”ã¨ã«200æ–‡å­—ç¨‹åº¦ã§é­…åŠ›ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚

                ï¼œåˆ¶ç´„ï¼
                ãƒ»ç´¹ä»‹ä¼æ¥­åã‚’æ˜ç¤ºçš„ã«æ›¸ã‹ãªã„ã§ã€èª¬æ˜ã ã‘æ›¸ã„ã¦ãã ã•ã„ã€‚
                ãƒ»å„ä¼æ¥­ã®ç´¹ä»‹æ–‡ã¯å¿…ãšåŠè§’ã®ã‚¢ãƒƒãƒˆãƒãƒ¼ã‚¯ã€Œ@ã€ã§åŒºåˆ‡ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å…¨è§’ã®ã‚¢ãƒƒãƒˆãƒãƒ¼ã‚¯ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
                ãƒ»ä¼æ¥­ç´¹ä»‹æ–‡ã®é•·ã•ã¯å¤§ä½“200å­—ç¨‹åº¦ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚å¤šå°‘å‰å¾Œã—ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€å°‘ãªã™ãã‚‹ã®ã¯æƒ…å ±ãŒè¶³ã‚Šãªã„ã¨æ€ã„ã¾ã™ã®ã§ã”é æ…®ãã ã•ã„ã€‚
                ãƒ»ä¸ãˆã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã«ã‚‚ç‰¹ç­†ã™ã¹ããã®ä¼æ¥­ç‹¬è‡ªã®ç‰¹å¾´ç­‰ãŒã‚ã‚Œã°æ˜¯éæ›¸ã„ã¦ãã ã•ã„ã€‚

                ï¼œå‡ºåŠ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼
                (ä¼æ¥­â‘ ã«ãŠã‘ã‚‹200å­—ç¨‹åº¦ã®ä¼æ¥­ç´¹ä»‹æ–‡)@(ä¼æ¥­â‘¡ã«ãŠã‘ã‚‹200å­—ç¨‹åº¦ã®ä¼æ¥­ç´¹ä»‹æ–‡)@(ä¼æ¥­â‘¢ã«ãŠã‘ã‚‹200å­—ç¨‹åº¦ã®ä¼æ¥­ç´¹ä»‹æ–‡)@...

                ï¼œä¼æ¥­è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼
                {company_details}
                """
            )
            prompt = ChatPromptTemplate.from_template(template)
            company_details = ""
            for company in companies:
                company_scores = "\n".join([f"- {feat}: {company[feat]:.1f}ç‚¹" for feat in features])
                company_details += f"ä¼æ¥­å: {company['ä¼æ¥­å']}\næ¥­ç•Œ: {company['æ¥­ç•Œ']}\nè©•ä¾¡ã‚¹ã‚³ã‚¢ (5ç‚¹æº€ç‚¹):\n{company_scores}\n\n"
            chain = prompt | llm | StrOutputParser()
            response = chain.invoke({"company_details": company_details})
            return response.strip()
        except Exception as e:
            return f"AIèª¬æ˜æ–‡ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    if search_button and not filtered_df.empty:
        user_vector = get_user_vector(user_preferences)
        company_vectors = np.array([get_company_vector(row) for _, row in filtered_df.iterrows()])
        if user_vector is not None and len(company_vectors) > 0:
            recommend_scores = calculate_recommend_scores(user_vector, company_vectors)
        else:
            recommend_scores = np.array([])
        if len(recommend_scores) == len(filtered_df):
            result_df = filtered_df.copy()
            result_df['ãŠã™ã™ã‚åº¦'] = recommend_scores
            result_df = result_df.sort_values(by='ãŠã™ã™ã‚åº¦', ascending=False).head(10)
        else:
            st.error("ãŠã™ã™ã‚åº¦ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            result_df = pd.DataFrame()

        # AIèª¬æ˜æ–‡ä¸€æ‹¬ç”Ÿæˆã¨åˆ†å‰²
        ai_descriptions = [""] * len(result_df)
        if use_ai_description and not result_df.empty:
            if not gemini_api_key:
                st.warning("ç’°å¢ƒå¤‰æ•°ã«GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIã«ã‚ˆã‚‹èª¬æ˜æ–‡ç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
                ai_descriptions = ["AIèª¬æ˜æ–‡ç”Ÿæˆä¸å¯ï¼ˆAPIã‚­ãƒ¼æœªè¨­å®šï¼‰"] * len(result_df)
            else:
                with st.spinner("AIãŒä¼æ¥­ã®ç‰¹å¾´ã‚’åˆ†æä¸­..."):
                    companies_data = result_df.to_dict('records')
                    bulk_text = generate_bulk_company_descriptions(companies_data, gemini_api_key)
                    # ã€Œ/ã€ã§åˆ†å‰²ã—ã€ä½™è¨ˆãªç©ºç™½ã‚„æ”¹è¡Œã‚’é™¤å»
                    ai_descriptions = [desc.strip() for desc in bulk_text.split("@") if desc.strip()]
                # ä¼æ¥­æ•°ã¨èª¬æ˜æ–‡æ•°ãŒä¸€è‡´ã—ãªã„å ´åˆã¯è£œæ­£
                if len(ai_descriptions) != len(result_df):
                    # è¶³ã‚Šãªã„å ´åˆã¯ç©ºæ–‡å­—ã§è£œå®Œ
                    ai_descriptions += [""] * (len(result_df) - len(ai_descriptions))
                ai_descriptions = ai_descriptions[:len(result_df)]
        else:
            ai_descriptions = ["AIã«ã‚ˆã‚‹èª¬æ˜æ–‡ç”Ÿæˆã¯ã‚ªãƒ•ã§ã™ã€‚"] * len(result_df)

        # çµæœãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«AIèª¬æ˜æ–‡åˆ—ã‚’è¿½åŠ 
        if not result_df.empty:
            result_df = result_df.reset_index(drop=True)
            result_df['èª¬æ˜æ–‡'] = ai_descriptions

        if not result_df.empty:
            st.subheader('ğŸ† ã‚ãªãŸã«ãŠã™ã™ã‚ã®ä¼æ¥­ãƒˆãƒƒãƒ—10')
            st.caption("ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã¨ä¼æ¥­ã®è©•ä¾¡ã®è¿‘ã•ï¼ˆãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ãƒ»ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰ã«åŸºã¥ãã€ãŠã™ã™ã‚åº¦ã‚’0ã€œ100ç‚¹ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ï¼ˆ100ç‚¹ãŒæœ€ã‚‚è¿‘ã„ï¼‰ã€‚")
            display_columns_match = ['ä¼æ¥­å', 'æ¥­ç•Œ', 'ç·åˆè©•ä¾¡', 'ãŠã™ã™ã‚åº¦'] + features
            st.dataframe(
                result_df[display_columns_match].style.format({
                    'ãŠã™ã™ã‚åº¦': '{:.2f}',
                    'ç·åˆè©•ä¾¡': '{:.2f}',
                    **{f: '{:.2f}' for f in features}
                }).background_gradient(subset=['ãŠã™ã™ã‚åº¦'], cmap='viridis'),
                hide_index=True
            )
            st.caption("è¡¨ã®é …ç›®åã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ä¸¦ã³æ›¿ãˆãŒã§ãã¾ã™ï¼ˆãŸã ã—è¡¨ç¤ºã¯ãƒˆãƒƒãƒ—10ã®ã¿ï¼‰ã€‚")
            st.subheader('ğŸ“Š ãƒãƒƒãƒãƒ³ã‚°ä¼æ¥­ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è©³ç´°')
            num_companies_to_show = len(result_df)
            tab_labels = [f"{i+1}ä½: {result_df.iloc[i]['ä¼æ¥­å']}" for i in range(num_companies_to_show)]
            tabs = st.tabs(tab_labels)
            for i, tab in enumerate(tabs):
                with tab:
                    company = result_df.iloc[i]
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        st.markdown(f"#### åŸºæœ¬æƒ…å ±")
                        st.metric("ãŠã™ã™ã‚åº¦", f"{company['ãŠã™ã™ã‚åº¦']:.2f}")
                        st.markdown(f"**ä¼æ¥­å:** {company['ä¼æ¥­å']}")
                        st.markdown(f"**æ¥­ç•Œ:** {company['æ¥­ç•Œ']}")
                        st.markdown(f"**ç·åˆè©•ä¾¡:** {company['ç·åˆè©•ä¾¡']:.2f}")
                        avg_salary = company.get('å¹³å‡å¹´å', np.nan)
                        avg_overtime = company.get('æ®‹æ¥­æ™‚é–“(æœˆé–“)', np.nan)
                        avg_vacation = company.get('æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡', np.nan)
                        st.markdown(f"**å¹³å‡å¹´å:** {avg_salary:.0f}ä¸‡å††" if pd.notna(avg_salary) else "å¹³å‡å¹´å: ãƒ‡ãƒ¼ã‚¿ãªã—")
                        st.markdown(f"**æ®‹æ¥­æ™‚é–“:** {avg_overtime:.1f}æ™‚é–“/æœˆ" if pd.notna(avg_overtime) else "æ®‹æ¥­æ™‚é–“: ãƒ‡ãƒ¼ã‚¿ãªã—")
                        st.markdown(f"**æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡:** {avg_vacation:.1f}%" if pd.notna(avg_vacation) else "æœ‰çµ¦æ¶ˆåŒ–ç‡: ãƒ‡ãƒ¼ã‚¿ãªã—")
                        # å€‹åˆ¥AIç´¹ä»‹æ–‡
                        st.markdown(f"**AIã«ã‚ˆã‚‹ä¼æ¥­ç´¹ä»‹:** {company.get('èª¬æ˜æ–‡', 'èª¬æ˜æ–‡ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚')}")
                        if 'URL' in company and pd.notna(company['URL']):
                            st.link_button("OpenWorkã§è©³ç´°ã‚’è¦‹ã‚‹", company['URL'])
                    with col2:
                        user_vector_radar = get_user_vector(user_preferences)
                        company_vector_radar = get_company_vector(company)
                        if user_vector_radar and company_vector_radar:
                            radar_chart = plot_radar_chart(
                                [user_vector_radar, company_vector_radar],
                                ['ã‚ãªãŸã®å¸Œæœ›', company['ä¼æ¥­å']],
                                f"{company['ä¼æ¥­å']} vs ã‚ãªãŸã®å¸Œæœ›"
                            )
                            if radar_chart:
                                st.plotly_chart(radar_chart, use_container_width=True)
                        else:
                            st.warning("ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                    st.markdown("---")
                    st.markdown("#### è©•ä¾¡é …ç›®ã®æ¯”è¼ƒ")
                    compare_items_data = {'é …ç›®': features}
                    compare_items_data['ã‚ãªãŸã®å¸Œæœ›'] = [f"{user_preferences[f]:.1f}" for f in features]
                    compare_items_data[company['ä¼æ¥­å']] = [f"{company.get(f, 'N/A'):.2f}" for f in features]
                    compare_items_df = pd.DataFrame(compare_items_data)
                    st.dataframe(compare_items_df.set_index('é …ç›®'), use_container_width=True)
        else:
            st.info("æ¡ä»¶ã«åˆã†ä¼æ¥­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.session_state['company_result_df'] = result_df if not result_df.empty else pd.DataFrame()
        st.session_state['user_prefs'] = user_preferences
    elif search_button and filtered_df.empty:
        pass
    else:
        st.info('ğŸ‘ˆ å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å¸Œæœ›æ¡ä»¶ã‚’è¨­å®šã—ã€ã€Œãƒãƒƒãƒãƒ³ã‚°é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚')


# --- æ¥­ç•Œãƒãƒƒãƒãƒ³ã‚°æ©Ÿèƒ½ (å¤‰æ›´ãªã—) ---
elif app_mode == "ğŸ“Š æ¥­ç•Œãƒãƒƒãƒãƒ³ã‚°":
    st.header("ğŸ“Š æ¥­ç•Œãƒãƒƒãƒãƒ³ã‚°")
    st.write("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ã—ãŸå¸Œæœ›æ¡ä»¶ã«åŸºã¥ãã€ãŠã™ã™ã‚ã®æ¥­ç•Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
    search_industry_button = st.sidebar.button('ğŸ“Š ãƒãƒƒãƒãƒ³ã‚°é–‹å§‹', key='match_industry_button')
    if search_industry_button:
        user_vector = get_user_vector(user_preferences)
        industry_vectors_dict = {name: get_industry_vector(avg_data) for name, avg_data in industry_avg.items()}
        valid_industry_names = [name for name, vec in industry_vectors_dict.items() if vec is not None]
        valid_industry_vectors = np.array([industry_vectors_dict[name] for name in valid_industry_names])
        if user_vector and len(valid_industry_vectors) > 0:
            recommend_scores_industry = calculate_recommend_scores(user_vector, valid_industry_vectors)
            scores_dict = {name: score for name, score in zip(valid_industry_names, recommend_scores_industry)}
        else:
            scores_dict = {}
        industry_match_data = []
        for industry_name in valid_industry_names:
            avg_data = industry_avg.get(industry_name, {})
            industry_match_data.append({
                'æ¥­ç•Œå': industry_name,
                'ãŠã™ã™ã‚åº¦': scores_dict.get(industry_name, 0.0),
                **avg_data
            })
        if industry_match_data:
            result_industry_df = pd.DataFrame(industry_match_data)
            result_industry_df = result_industry_df.sort_values(by='ãŠã™ã™ã‚åº¦', ascending=False).head(10).reset_index(drop=True)
            st.subheader('ğŸ† ã‚ãªãŸã«ãŠã™ã™ã‚ã®æ¥­ç•Œãƒˆãƒƒãƒ—10')
            st.caption("ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã¨æ¥­ç•Œå¹³å‡è©•ä¾¡ã®è¿‘ã•ï¼ˆãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ãƒ»ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰ã«åŸºã¥ãã€ãŠã™ã™ã‚åº¦ã‚’0ã€œ100ç‚¹ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ï¼ˆ100ç‚¹ãŒæœ€ã‚‚è¿‘ã„ï¼‰ã€‚")
            display_columns_industry = ['æ¥­ç•Œå', 'ãŠã™ã™ã‚åº¦'] + features
            st.dataframe(
                result_industry_df[display_columns_industry].style.format({
                    'ãŠã™ã™ã‚åº¦': '{:.2f}',
                    **{f: '{:.2f}' for f in features}
                }).background_gradient(subset=['ãŠã™ã™ã‚åº¦'], cmap='viridis'),
                hide_index=True
            )
            st.caption("è¡¨ã®é …ç›®åã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ä¸¦ã³æ›¿ãˆãŒã§ãã¾ã™ï¼ˆãŸã ã—è¡¨ç¤ºã¯ãƒˆãƒƒãƒ—10ã®ã¿ï¼‰ã€‚")
            st.subheader('ğŸ“Š ãƒãƒƒãƒãƒ³ã‚°æ¥­ç•Œã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è©³ç´°')

            # --- AIã«ã‚ˆã‚‹æ¥­ç•Œç´¹ä»‹æ–‡ã‚’ãƒˆãƒƒãƒ—10åˆ†ã¾ã¨ã‚ã¦ä¸€æ‹¬ç”Ÿæˆ ---
            gemini_api_key = os.environ.get("GEMINI_API_KEY")
            ai_desc_list = [""] * len(result_industry_df)
            if gemini_api_key:
                try:
                    llm = ChatGoogleGenerativeAI(
                        model="gemini-1.5-flash",
                        temperature=0.7,
                        convert_system_message_to_human=False,
                        google_api_key=gemini_api_key
                    )
                    from langchain_core.prompts import ChatPromptTemplate
                    from langchain_core.output_parsers import StrOutputParser
                    template = (
                        "ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®æ¥­ç•Œæƒ…å ±ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶ã‚’ã‚‚ã¨ã«ã€"
                        "å„æ¥­ç•ŒãŒã©ã‚Œã ã‘ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›ã«åˆã£ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¤ã¤ã€200å­—ä»¥å†…ã§æ¥­ç•Œã®é­…åŠ›ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚"
                        "å„æ¥­ç•Œã®ç´¹ä»‹æ–‡ã¯å¿…ãšåŠè§’ã®ã‚¢ãƒƒãƒˆãƒãƒ¼ã‚¯ã€Œ@ã€ã§åŒºåˆ‡ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
                        "{industry_details}"
                    )
                    prompt = ChatPromptTemplate.from_template(template)
                    industry_details = ""
                    for idx, row in result_industry_df.iterrows():
                        industry_scores = "\n".join([f"- {feat}: {row.get(feat, 0):.1f}ç‚¹" for feat in features])
                        user_scores = "\n".join([f"- {feat}: {user_preferences.get(feat, 0):.1f}ç‚¹" for feat in features])
                        industry_details += (
                            f"æ¥­ç•Œå: {row['æ¥­ç•Œå']}\n"
                            f"æ¥­ç•Œã‚¹ã‚³ã‚¢:\n{industry_scores}\n"
                            f"ãƒ¦ãƒ¼ã‚¶ãƒ¼å¸Œæœ›:\n{user_scores}\n\n"
                        )
                    chain = prompt | llm | StrOutputParser()
                    with st.spinner("AIãŒæ¥­ç•Œã®ç‰¹å¾´ã‚’åˆ†æä¸­..."):
                        ai_bulk = chain.invoke({"industry_details": industry_details})
                        ai_desc_list = [desc.strip() for desc in ai_bulk.split("@") if desc.strip()]
                    if len(ai_desc_list) != len(result_industry_df):
                        ai_desc_list += [""] * (len(result_industry_df) - len(ai_desc_list))
                    ai_desc_list = ai_desc_list[:len(result_industry_df)]
                except Exception as e:
                    ai_desc_list = [f"AIèª¬æ˜æ–‡ç”Ÿæˆã«å¤±æ•—: {e}"] * len(result_industry_df)
            else:
                ai_desc_list = ["AIã«ã‚ˆã‚‹æ¥­ç•Œç´¹ä»‹æ–‡ç”Ÿæˆã¯APIã‚­ãƒ¼æœªè¨­å®šã®ãŸã‚åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"] * len(result_industry_df)

            # --- å„ã‚¿ãƒ–ã§å€‹åˆ¥ã«AIç´¹ä»‹æ–‡ã‚’è¡¨ç¤º ---
            num_industries_to_show = len(result_industry_df)
            industry_tab_labels = [f"{i+1}ä½: {result_industry_df.iloc[i]['æ¥­ç•Œå']}" for i in range(num_industries_to_show)]
            industry_tabs = st.tabs(industry_tab_labels)
            for i, tab in enumerate(industry_tabs):
                with tab:
                    industry_info = result_industry_df.iloc[i]
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        st.markdown(f"#### åŸºæœ¬æƒ…å ± (å¹³å‡å€¤)")
                        st.metric("ãŠã™ã™ã‚åº¦", f"{industry_info['ãŠã™ã™ã‚åº¦']:.2f}")
                        st.markdown(f"**æ¥­ç•Œå:** {industry_info['æ¥­ç•Œå']}")
                        avg_salary = industry_info.get('å¹³å‡å¹´å', np.nan)
                        avg_overtime = industry_info.get('æ®‹æ¥­æ™‚é–“(æœˆé–“)', np.nan)
                        avg_vacation = industry_info.get('æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡', np.nan)
                        st.markdown(f"**å¹³å‡å¹´å:** {avg_salary:.0f}ä¸‡å††" if pd.notna(avg_salary) else "å¹³å‡å¹´å: ãƒ‡ãƒ¼ã‚¿ãªã—")
                        st.markdown(f"**æ®‹æ¥­æ™‚é–“:** {avg_overtime:.1f}æ™‚é–“/æœˆ" if pd.notna(avg_overtime) else "æ®‹æ¥­æ™‚é–“: ãƒ‡ãƒ¼ã‚¿ãªã—")
                        st.markdown(f"**æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡:** {avg_vacation:.1f}%" if pd.notna(avg_vacation) else "æœ‰çµ¦æ¶ˆåŒ–ç‡: ãƒ‡ãƒ¼ã‚¿ãªã—")
                        st.markdown(f"**AIã«ã‚ˆã‚‹æ¥­ç•Œç´¹ä»‹:** {ai_desc_list[i] if i < len(ai_desc_list) else 'èª¬æ˜æ–‡ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'}")
                    with col2:
                        user_vector_radar = get_user_vector(user_preferences)
                        industry_vector_radar = get_industry_vector(industry_info)
                        if user_vector_radar and industry_vector_radar:
                            radar_chart_industry = plot_radar_chart(
                                [user_vector_radar, industry_vector_radar],
                                ['ã‚ãªãŸã®å¸Œæœ›', f"{industry_info['æ¥­ç•Œå']} (å¹³å‡)"],
                                f"{industry_info['æ¥­ç•Œå']} å¹³å‡ vs ã‚ãªãŸã®å¸Œæœ›"
                            )
                            if radar_chart_industry:
                                st.plotly_chart(radar_chart_industry, use_container_width=True)
                        else:
                            st.warning("ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
                    st.markdown("---")
                    st.markdown("#### è©•ä¾¡é …ç›® (å¹³å‡å€¤)")
                    compare_industry_items_data = {'é …ç›®': features}
                    compare_industry_items_data['ã‚ãªãŸã®å¸Œæœ›'] = [f"{user_preferences[f]:.1f}" for f in features]
                    compare_industry_items_data[f"{industry_info['æ¥­ç•Œå']} (å¹³å‡)"] = [f"{industry_info.get(f, np.nan):.2f}" for f in features]
                    compare_industry_items_df = pd.DataFrame(compare_industry_items_data)
                    st.dataframe(compare_industry_items_df.set_index('é …ç›®'), use_container_width=True)
        else:
            st.info("æ¡ä»¶ã«åˆã†æ¥­ç•ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.session_state['industry_result_df'] = result_industry_df
        st.session_state['user_prefs'] = user_preferences
    else:
        st.info('ğŸ‘ˆ å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å¸Œæœ›æ¡ä»¶ã‚’è¨­å®šã—ã€ã€Œãƒãƒƒãƒãƒ³ã‚°é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚')

# --- ä¼æ¥­æ¯”è¼ƒæ©Ÿèƒ½ (å¤‰æ›´ãªã—) ---
elif app_mode == "ğŸ”„ ä¼æ¥­æ¯”è¼ƒ":
    st.header('ğŸ”„ ä¼æ¥­æ¯”è¼ƒ')
    if 'company_result_df' not in st.session_state or st.session_state['company_result_df'].empty: st.warning("âš ï¸ ã¾ãšã€Œä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°ã€æ©Ÿèƒ½ã§ä¼æ¥­ã‚’æ¤œç´¢ã—ã€æ¯”è¼ƒã—ãŸã„ä¼æ¥­å€™è£œã‚’è¡¨ç¤ºã•ã›ã¦ãã ã•ã„ã€‚")
    else:
        result_df = st.session_state['company_result_df']
        user_prefs = st.session_state.get('user_prefs')
        st.subheader('æ¯”è¼ƒã™ã‚‹ä¼æ¥­ã‚’é¸æŠ')
        company_options = {f"{i+1}ä½ ({result_df.iloc[i]['ãŠã™ã™ã‚åº¦']:.2f}): {result_df.iloc[i]['ä¼æ¥­å']}": i for i in range(len(result_df))}
        col1, col2 = st.columns(2)
        with col1: selected_label1 = st.selectbox('1ã¤ç›®ã®ä¼æ¥­', company_options.keys(), index=0, key='compare_company1'); company1_idx = company_options[selected_label1]
        with col2: selected_label2 = st.selectbox('2ã¤ç›®ã®ä¼æ¥­', company_options.keys(), index=min(1, len(result_df)-1), key='compare_company2'); company2_idx = company_options[selected_label2]
        company1 = result_df.iloc[company1_idx]; company2 = result_df.iloc[company2_idx]
        st.subheader('ğŸ“Š æ¯”è¼ƒçµæœ'); st.markdown("#### ä¸»è¦æƒ…å ±ã¨è©•ä¾¡é …ç›®")
        compare_data_disp = {'é …ç›®': ['ãŠã™ã™ã‚åº¦', 'æ¥­ç•Œ', 'ç·åˆè©•ä¾¡', 'å¹³å‡å¹´å', 'æ®‹æ¥­æ™‚é–“(æœˆé–“)', 'æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡'] + features}
        
        compare_data_disp[company1['ä¼æ¥­å']] = [format_compare_value(company1, item) for item in compare_data_disp['é …ç›®']]
        compare_data_disp[company2['ä¼æ¥­å']] = [format_compare_value(company2, item) for item in compare_data_disp['é …ç›®']]
        show_user_in_table = st.checkbox("æ¯”è¼ƒè¡¨ã«ã‚ãªãŸã®å¸Œæœ›ã‚‚è¡¨ç¤º", value=False, key='compare_table_show_user')
        if show_user_in_table and user_prefs:
            user_values = ["-", "-", "-"] + ["-", "-", "-"] + [f"{user_prefs[f]:.1f}" for f in features]
            compare_data_disp['ã‚ãªãŸã®å¸Œæœ›'] = user_values
        compare_disp_df = pd.DataFrame(compare_data_disp); st.dataframe(compare_disp_df.set_index('é …ç›®'), use_container_width=True)
        st.subheader('ğŸ“ˆ è©•ä¾¡é …ç›®æ¯”è¼ƒ (1-5ç‚¹)'); vectors_to_plot = []; labels_to_plot = []
        company1_vector_radar = get_company_vector(company1); company2_vector_radar = get_company_vector(company2)
        if company1_vector_radar: vectors_to_plot.append(company1_vector_radar); labels_to_plot.append(company1['ä¼æ¥­å'])
        if company2_vector_radar: vectors_to_plot.append(company2_vector_radar); labels_to_plot.append(company2['ä¼æ¥­å'])
        show_user_in_radar = st.checkbox("ã‚°ãƒ©ãƒ•ã«ã‚ãªãŸã®å¸Œæœ›ã‚‚è¡¨ç¤º", value=True, key='compare_radar_show_user')
        if show_user_in_radar and user_prefs:
            user_vector_radar = get_user_vector(user_preferences);
        if user_vector_radar: vectors_to_plot.insert(0, user_vector_radar); labels_to_plot.insert(0, 'ã‚ãªãŸã®å¸Œæœ›')
        if vectors_to_plot:
            radar_chart_compare = plot_radar_chart(vectors_to_plot, labels_to_plot, f"è©•ä¾¡é …ç›®æ¯”è¼ƒ")
            if radar_chart_compare: st.plotly_chart(radar_chart_compare, use_container_width=True)
        else: st.warning("æ¯”è¼ƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.subheader('ğŸ”— è©³ç´°æƒ…å ± (OpenWork)'); col1_link, col2_link = st.columns(2)
        with col1_link:
            if 'URL' in company1 and pd.notna(company1['URL']): st.link_button(f"{company1['ä¼æ¥­å']} ã®ãƒšãƒ¼ã‚¸ã¸", company1['URL'])
        with col2_link:
            if 'URL' in company2 and pd.notna(company2['URL']): st.link_button(f"{company2['ä¼æ¥­å']} ã®ãƒšãƒ¼ã‚¸ã¸", company2['URL'])

# --- æ¥­ç•Œæ¯”è¼ƒæ©Ÿèƒ½ (å¤‰æ›´ãªã—) ---
elif app_mode == "ğŸŒ æ¥­ç•Œæ¯”è¼ƒ":
    st.header("ğŸŒ æ¥­ç•Œæ¯”è¼ƒ")
    st.write("é¸æŠã—ãŸæ¥­ç•Œã®å¹³å‡ãƒ‡ãƒ¼ã‚¿ï¼ˆã¾ãŸã¯ã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ï¼‰ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")
    st.subheader('æ¯”è¼ƒã™ã‚‹æ¥­ç•Œã‚’é¸æŠ')
    available_industries = ['å…¨æ¥­ç•Œ'] + industries_for_analysis
    col1, col2 = st.columns(2)
    with col1: selected_industry1 = st.selectbox("1ã¤ç›®ã®æ¥­ç•Œ", available_industries, index=0, key='compare_industry1')
    with col2: selected_industry2 = st.selectbox("2ã¤ç›®ã®æ¥­ç•Œ", available_industries, index=min(1, len(available_industries)-1), key='compare_industry2')
    industry1_avg_data = industry_avg.get(selected_industry1); industry2_avg_data = industry_avg.get(selected_industry2)
    st.subheader('ğŸ“Š æ¯”è¼ƒçµæœ'); st.markdown("#### è©•ä¾¡é …ç›®ã¨å‚è€ƒæƒ…å ± (å¹³å‡å€¤)")
    compare_industry_data = {'é …ç›®': features + display_numerical_features}
    
    compare_industry_data[f"{selected_industry1} (å¹³å‡)"] = [format_industry_compare_value(industry1_avg_data, item) for item in compare_industry_data['é …ç›®']]
    compare_industry_data[f"{selected_industry2} (å¹³å‡)"] = [format_industry_compare_value(industry2_avg_data, item) for item in compare_industry_data['é …ç›®']]
    show_user_in_industry_table = st.checkbox("æ¯”è¼ƒè¡¨ã«ã‚ãªãŸã®å¸Œæœ›ã‚‚è¡¨ç¤º", value=False, key='compare_industry_table_show_user')
    
    user_prefs = st.session_state.get('user_prefs')
    if show_user_in_industry_table and user_prefs:
        user_values = [f"{user_preferences[f]:.1f}" for f in features] + ["-", "-", "-"]
        compare_industry_data['ã‚ãªãŸã®å¸Œæœ›'] = user_values
    compare_industry_df = pd.DataFrame(compare_industry_data); st.dataframe(compare_industry_df.set_index('é …ç›®'), use_container_width=True)
    st.subheader('ğŸ“ˆ è©•ä¾¡é …ç›®æ¯”è¼ƒ (1-5ç‚¹å¹³å‡)'); industry_vectors_to_plot = []; industry_labels_to_plot = []
    industry1_vector_radar = get_industry_vector(industry1_avg_data); industry2_vector_radar = get_industry_vector(industry2_avg_data)
    if industry1_vector_radar: industry_vectors_to_plot.append(industry1_vector_radar); industry_labels_to_plot.append(f"{selected_industry1} (å¹³å‡)")
    if industry2_vector_radar: industry_vectors_to_plot.append(industry2_vector_radar); industry_labels_to_plot.append(f"{selected_industry2} (å¹³å‡)")
    show_user_in_industry_radar = st.checkbox("ã‚°ãƒ©ãƒ•ã«ã‚ãªãŸã®å¸Œæœ›ã‚‚è¡¨ç¤º", value=True, key='compare_industry_radar_show_user')
    if show_user_in_industry_radar: user_vector_radar = get_user_vector(user_preferences)
    if user_vector_radar: industry_vectors_to_plot.insert(0, user_vector_radar); industry_labels_to_plot.insert(0, 'ã‚ãªãŸã®å¸Œæœ›')
    if industry_vectors_to_plot:
        radar_chart_industry_compare = plot_radar_chart(industry_vectors_to_plot, industry_labels_to_plot, f"æ¥­ç•Œè©•ä¾¡é …ç›®æ¯”è¼ƒ")
        if radar_chart_industry_compare: st.plotly_chart(radar_chart_industry_compare, use_container_width=True)
    else: st.warning("æ¯”è¼ƒã™ã‚‹æ¥­ç•Œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# --- æ¥­ç•Œãƒ»ä¼æ¥­åˆ†ææ©Ÿèƒ½ï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆæ¨ªä¸¦ã³ä¿®æ­£ç‰ˆï¼‰ ---
# --- æ¥­ç•Œãƒ»ä¼æ¥­åˆ†ææ©Ÿèƒ½ï¼ˆãŠã™ã™ã‚åº¦æ­£è¦åŒ–ï¼†æ¥­ç•Œç´¹ä»‹æ–‡å…¨æ¥­ç•Œåˆ†ï¼‰ ---
elif app_mode == "ğŸ“ˆ æ¥­ç•Œãƒ»ä¼æ¥­åˆ†æ":
    st.header('ğŸ“ˆ æ¥­ç•Œãƒ»ä¼æ¥­åˆ†æ')
    st.write("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸã‚ãªãŸã®å¸Œæœ›æ¡ä»¶ã¨ã€ç‰¹å®šã®æ¥­ç•Œå¹³å‡ã¾ãŸã¯ç‰¹å®šã®ä¼æ¥­ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")
    user_vector_analysis = get_user_vector(user_preferences)
    if user_vector_analysis is None:
        st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼å¸Œæœ›æ¡ä»¶ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()
    st.subheader('æ¯”è¼ƒå¯¾è±¡ã®é¸æŠ')
    analysis_comparison_type = st.radio(
        "æ¯”è¼ƒå¯¾è±¡ã‚’é¸æŠã—ã¦ãã ã•ã„", ["æ¥­ç•Œå¹³å‡ã¨æ¯”è¼ƒ", "ç‰¹å®šã®ä¼æ¥­ã¨æ¯”è¼ƒ"],
        key="analysis_comparison_type", horizontal=True
    )

    if analysis_comparison_type == "æ¥­ç•Œå¹³å‡ã¨æ¯”è¼ƒ":
        available_industries = ['å…¨æ¥­ç•Œ'] + industries_for_analysis
        selected_industry_analysis = st.selectbox('æ¯”è¼ƒã—ãŸã„æ¥­ç•Œã‚’é¸æŠ', available_industries, key="analysis_industry_select")

        # --- ãŠã™ã™ã‚åº¦ã‚’å…¨æ¥­ç•Œã§è¨ˆç®—ã—ã€è©²å½“æ¥­ç•Œã®ã¿ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ— ---
        industry_vectors_dict = {name: get_industry_vector(avg_data) for name, avg_data in industry_avg.items()}
        valid_industry_names = [name for name, vec in industry_vectors_dict.items() if vec is not None]
        valid_industry_vectors = np.array([industry_vectors_dict[name] for name in valid_industry_names])
        user_vec = get_user_vector(user_preferences)
        selected_score = None
        if user_vec is not None and len(valid_industry_vectors) > 0:
            recommend_scores = calculate_recommend_scores(user_vec, valid_industry_vectors)
            industry_score_dict = {name: score for name, score in zip(valid_industry_names, recommend_scores)}
            selected_score = industry_score_dict.get(selected_industry_analysis, None)

        industry_avg_data = industry_avg.get(selected_industry_analysis)
        industry_vector_analysis = get_industry_vector(industry_avg_data) if industry_avg_data else None

        col1, col2 = st.columns([1, 1])
        with col1:
            st.markdown(f"#### åŸºæœ¬æƒ…å ± (å¹³å‡å€¤)")
            st.metric("ãŠã™ã™ã‚åº¦", f"{selected_score:.2f}" if selected_score is not None else "N/A")
            st.markdown(f"**æ¥­ç•Œå:** {selected_industry_analysis}")
            st.markdown(f"**ç·åˆè©•ä¾¡:** {industry_avg_data.get('ç·åˆè©•ä¾¡', 'N/A'):.2f}" if industry_avg_data and 'ç·åˆè©•ä¾¡' in industry_avg_data else "ç·åˆè©•ä¾¡: ãƒ‡ãƒ¼ã‚¿ãªã—")
            avg_salary = industry_avg_data.get('å¹³å‡å¹´å', np.nan) if industry_avg_data else np.nan
            avg_overtime = industry_avg_data.get('æ®‹æ¥­æ™‚é–“(æœˆé–“)', np.nan) if industry_avg_data else np.nan
            avg_vacation = industry_avg_data.get('æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡', np.nan) if industry_avg_data else np.nan
            st.markdown(f"**å¹³å‡å¹´å:** {avg_salary:.0f}ä¸‡å††" if pd.notna(avg_salary) else "å¹³å‡å¹´å: ãƒ‡ãƒ¼ã‚¿ãªã—")
            st.markdown(f"**æ®‹æ¥­æ™‚é–“:** {avg_overtime:.1f}æ™‚é–“/æœˆ" if pd.notna(avg_overtime) else "æ®‹æ¥­æ™‚é–“: ãƒ‡ãƒ¼ã‚¿ãªã—")
            st.markdown(f"**æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡:** {avg_vacation:.1f}%" if pd.notna(avg_vacation) else "æœ‰çµ¦æ¶ˆåŒ–ç‡: ãƒ‡ãƒ¼ã‚¿ãªã—")
            st.markdown(f"**AIã«ã‚ˆã‚‹æ¥­ç•Œç´¹ä»‹:** {industry_intros.get(selected_industry_analysis, 'ï¼ˆç´¹ä»‹æ–‡æœªè¨­å®šï¼‰')}")
        with col2:
            if industry_vector_analysis is not None:
                radar_chart_industry = plot_radar_chart(
                    [user_vector_analysis, industry_vector_analysis],
                    ['ã‚ãªãŸã®å¸Œæœ›', f'{selected_industry_analysis} (å¹³å‡)'],
                    f"{selected_industry_analysis} å¹³å‡ vs ã‚ãªãŸã®å¸Œæœ›"
                )
                if radar_chart_industry:
                    st.plotly_chart(radar_chart_industry, use_container_width=True)
            else:
                st.warning("æ¥­ç•Œå¹³å‡ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.markdown("---")
        st.markdown("#### è©•ä¾¡é …ç›® (å¹³å‡å€¤)")
        if industry_avg_data:
            industry_info_disp = {
                'é …ç›®': features + display_numerical_features,
                'å¹³å‡å€¤': [format_industry_compare_value(industry_avg_data, f) for f in features]
                            + [format_industry_compare_value(industry_avg_data, nf) for nf in display_numerical_features]
            }
            st.dataframe(pd.DataFrame(industry_info_disp).set_index('é …ç›®'), use_container_width=True)
        else:
            st.error(f"ã€Œ{selected_industry_analysis}ã€ã®å¹³å‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    else:
        selected_company_analysis = st.selectbox('æ¯”è¼ƒã—ãŸã„ä¼æ¥­ã‚’é¸æŠ', company_names_list, index=default_company_index, key="analysis_company_select")
        # --- ãŠã™ã™ã‚åº¦ã‚’å…¨ä¼æ¥­ã§è¨ˆç®—ã—ã€è©²å½“ä¼æ¥­ã®ã¿ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ— ---
        user_vec = get_user_vector(user_preferences)
        company_vectors = np.array([get_company_vector(row) for _, row in df.iterrows()])
        all_company_names = df['ä¼æ¥­å'].tolist()
        selected_score = None
        if user_vec is not None and len(company_vectors) > 0:
            recommend_scores = calculate_recommend_scores(user_vec, company_vectors)
            company_score_dict = {name: score for name, score in zip(all_company_names, recommend_scores)}
            selected_score = company_score_dict.get(selected_company_analysis, None)

        company_data_analysis_series = df[df['ä¼æ¥­å'] == selected_company_analysis].iloc[0] if not df[df['ä¼æ¥­å'] == selected_company_analysis].empty else None
        company_vector_analysis = get_company_vector(company_data_analysis_series) if company_data_analysis_series is not None else None

        col1, col2 = st.columns([1, 1])
        with col1:
            st.markdown(f"#### åŸºæœ¬æƒ…å ±")
            st.metric("ãŠã™ã™ã‚åº¦", f"{selected_score:.2f}" if selected_score is not None else "N/A")
            if company_data_analysis_series is not None:
                st.markdown(f"**ä¼æ¥­å:** {company_data_analysis_series['ä¼æ¥­å']}")
                st.markdown(f"**æ¥­ç•Œ:** {company_data_analysis_series['æ¥­ç•Œ']}")
                st.markdown(f"**ç·åˆè©•ä¾¡:** {company_data_analysis_series.get('ç·åˆè©•ä¾¡', np.nan):.2f}")
                avg_salary = company_data_analysis_series.get('å¹³å‡å¹´å', np.nan)
                avg_overtime = company_data_analysis_series.get('æ®‹æ¥­æ™‚é–“(æœˆé–“)', np.nan)
                avg_vacation = company_data_analysis_series.get('æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡', np.nan)
                st.markdown(f"**å¹³å‡å¹´å:** {avg_salary:.0f}ä¸‡å††" if pd.notna(avg_salary) else "å¹³å‡å¹´å: ãƒ‡ãƒ¼ã‚¿ãªã—")
                st.markdown(f"**æ®‹æ¥­æ™‚é–“:** {avg_overtime:.1f}æ™‚é–“/æœˆ" if pd.notna(avg_overtime) else "æ®‹æ¥­æ™‚é–“: ãƒ‡ãƒ¼ã‚¿ãªã—")
                st.markdown(f"**æœ‰çµ¦ä¼‘æš‡æ¶ˆåŒ–ç‡:** {avg_vacation:.1f}%" if pd.notna(avg_vacation) else "æœ‰çµ¦æ¶ˆåŒ–ç‡: ãƒ‡ãƒ¼ã‚¿ãªã—")
                # AIã«ã‚ˆã‚‹ä¼æ¥­ç´¹ä»‹ï¼ˆå¾“æ¥é€šã‚Šã€å¿…è¦ãªã‚‰ç”Ÿæˆï¼‰
                gemini_api_key = os.environ.get("GEMINI_API_KEY")
                ai_desc = ""
                if gemini_api_key:
                    with st.spinner("AIãŒä¼æ¥­ã®ç‰¹å¾´ã‚’åˆ†æä¸­..."):
                        desc_text = generate_company_descriptions([company_data_analysis_series], gemini_api_key)
                        if isinstance(desc_text, list) and len(desc_text) > 0:
                            ai_desc = desc_text[0].strip()
                        elif isinstance(desc_text, str):
                            ai_desc = desc_text.strip()
                st.markdown(f"**AIã«ã‚ˆã‚‹ä¼æ¥­ç´¹ä»‹:** {ai_desc if ai_desc else 'èª¬æ˜æ–‡ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'}")
                if 'URL' in company_data_analysis_series and pd.notna(company_data_analysis_series['URL']):
                    st.link_button("OpenWorkã§è©³ç´°ã‚’è¦‹ã‚‹", company_data_analysis_series['URL'])
        with col2:
            if company_vector_analysis is not None:
                radar_chart_company = plot_radar_chart(
                    [user_vector_analysis, company_vector_analysis],
                    ['ã‚ãªãŸã®å¸Œæœ›', company_data_analysis_series['ä¼æ¥­å']],
                    f"{company_data_analysis_series['ä¼æ¥­å']} vs ã‚ãªãŸã®å¸Œæœ›"
                )
                if radar_chart_company:
                    st.plotly_chart(radar_chart_company, use_container_width=True)
            else:
                st.warning("ä¼æ¥­ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.markdown("---")
        st.markdown("#### è©•ä¾¡é …ç›®")
        if company_data_analysis_series is not None:
            company_info_disp = {
                'é …ç›®': features + display_numerical_features,
                'å€¤': [f"{company_data_analysis_series.get(f, np.nan):.2f}" for f in features] +
                       [format_compare_value(company_data_analysis_series, nf) for nf in display_numerical_features]
            }
            st.dataframe(pd.DataFrame(company_info_disp).set_index('é …ç›®'), use_container_width=True)
        else:
            st.error(f"ã€Œ{selected_company_analysis}ã€ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# --- ãƒ•ãƒƒã‚¿ãƒ¼ (å¤‰æ›´ãªã—) ---
st.markdown('---')
st.markdown("""
<div style="text-align: center; color: gray; font-size: 0.8em;">
    Â© 2025 ä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°ã‚¢ãƒ—ãƒª | ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ•™è‚²ãŠã‚ˆã³ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç›®çš„ã§ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚
</div>
""", unsafe_allow_html=True)
